---
layout: post
title: CVPR 2019 论文概要汇总
category: Document
tags: cvpr
date: 2019-07-08 15:07:41
published: true
summary: CVPR 2019 论文汇总
image: pirates.svg
comment: true
---

### 56、[CVPR2019 | 旷视研究院提出TACNet，刷新时空动作检测技术新高度](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247489201&idx=2&sn=c609cdc61cc5cd8482a6eda8376bd590&chksm=ec1ffb48db68725ee68c4e0fea02c539f4e18c12d1cc787a8931411276bc7f8dfd2b3b96f3de&token=960372681&lang=zh_CN#rd)

旷视研究院(R4D组)提出一个过渡感知的上下文网络——TACNet，可以显著提升时空动作检测的性能。


### 55、[CVPR 2019 | 国防科大提出双目超分辨算法，效果优异代码已开源](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247489168&idx=2&sn=4e5a291b3ba5fedb3383b76ca15f6512&chksm=ec1ffb69db68727fa7fc8b8bc8a1fe8a37f69c8a708677bc1d5cd8fcbb07a99a138d7014b41c&token=960372681&lang=zh_CN#rd)

来自国防科技大学等单位的学者提出了新型双目超分辨算法，充分利用了左右图的信息提升图像超分辨效果；另外，他们构建了一个大型双目图像超分辨数据集，用于双目图像超分辨算法的训练和评估。代码已开源。


### 54、[CVPR2019 | 港中文&腾讯优图等提出：暗光下的图像增强](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247489157&idx=2&sn=8887c69f23512cdd48a65a95216a7502&chksm=ec1ffb7cdb68726a4cd1b34d5ac430ebb03b02b1508ba217b7c4c5617a360c500b4f4ae2f511&token=960372681&lang=zh_CN#rd)

提出基于深度学习优化光照的暗光下的图像增强模型，用端到端网络增强曝光不足的照片。


### 53、[CVPR2019 | AR版“神笔马良”：从单张2D图片建立3D人物运动模型，华盛顿大学与Facebook 3D重建](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247489137&idx=1&sn=81fb42a72fecf45dc04689c22c81ceed&chksm=ec1ffb88db68729e712e7d9b2cd79d7fefd9acc9295aeff6838bdf6b211b8bbe8c13f9300f67&token=960372681&lang=zh_CN#rd)

华盛顿大学与Facebook的CVPR论文，从一张普通的2D图片建立一个活生生的3D人物运动模型。


### 52、[CVPR2019 | 文本检测算法综述](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247489078&idx=1&sn=8486e661e48cee147e0fdcd0b06ce9e4&chksm=ec1ffbcfdb6872d965f7b10f29598828999e609b6fc3d3023ff74d3c2a714068f106c1326a9c&token=960372681&lang=zh_CN#rd)
简要分享CVPR2019关于文本检测的几个工作，后期还会补充。


### 51、[CVPR2019 | 快、好、实现简单并且开源的显著性检测方法](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247488939&idx=1&sn=017c79c2b7b91de81ec34ca812c2228f&chksm=ec1ff852db68714474a444cd2d59b98933ed741ffd8ddc850ad1619d11052580acb4c54b8e72&token=167381780&lang=zh_CN#rd)

本文提出一种又快又好的显著性检测方法，与DSS相比，无论是分数还是性能都有较大提升，代码已开源。


### 50、[CVPR2019 | 旷视研究院提出新型损失函数：改善边界框模糊问题](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247488887&idx=2&sn=47043e73b8fee0ba20ea9303d212dd1a&chksm=ec1ff88edb687198f2e392a3edaaec82e500e432e674fdd9a14c018d77057bf4c53fac822d34&token=167381780&lang=zh_CN#rd)

旷视研究院CVPR 2019的工作，本文提出了一种新的带有不确定性的边界框回归损失，可用于学习更准确的目标定位。


### 49、[CVPR2019 | ASRCF：基于自适应空间加权相关滤波的视觉跟踪研究（即将开源）](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247488891&idx=1&sn=e436c1fa403fc06fe076f5167bc9dffa&chksm=ec1ff882db6871943e04b8b12845c107f70a81cb8c3b6ddf358dbccbcdfa455ed3d37d136e63&token=167381780&lang=zh_CN#rd)

本文提出自适应空间约束相关滤波算法来同时优化滤波器权重及空间约束矩阵。大量的在综合数据集上的实验结果证明了本文所提出的算法可以与现有的先进算法取得相当的跟踪结果，并且达到了实时的跟踪速度。


### 48、[CVPR2019 | 10 分钟看完：悉尼科技大学入选 CVPR 2019 的 8 篇论文，都研究什么？](http://bbs.cvmart.net/articles/402/10-fen-zhong-kan-wan-xi-ni-ke-ji-da-xue-ru-xuan-cvpr-2019-de-8-pian-lun-wen-dou-yan-jiu-shen-me)

本文介绍了悉尼科技大学杨易教授组8 篇CVPR 2019论文（3 篇Oral），包括行人重识别/生成，迁移学习，网络结构搜索，图像生成， 网络压缩等领域的工作。


### 47、[CVPR2019 Oral | Relation-Shape CNN：以几何关系卷积推理点云 3D 形状](http://bbs.cvmart.net/articles/404/cvpr2019-oral-relation-shape-cnn-yi-ji-he-guan-xi-juan-ji-tui-li-dian-yun-3d-xing-zhuang)

来自中科院自动化所模式识别国家重点实验室的研究者提出了Relation-Shape CNN，将经典的2D CNN拓展至3D点云领域进行几何关系学习，该方法在三个主流的点云分析任务上均实现了优秀的性能。


### 46、[CVPR2019 | 不同视角构造cycle-consistency，降低视频标注成本](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247488680&idx=1&sn=a3d744d9592ba737ed4bc77830f9f098&chksm=ec1ff951db68704753729d0c26a27d0c969580e6c1017882f130350219e1114f28b76fba080e&token=236193575&lang=zh_CN#rd)

本文介绍的两篇文章从不同视角来构造cycle-consistency约束，目标都是为了在不需要标注label情况下，学到更好的视频representation，这也是解决在real-world中大规模无标注视频数据的低利用率及高昂的frame-level人工标注成本等问题。


### 45、[CVPR2019 | 旷视实时语义分割技术DFANet：高清虚化无需双摄](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247488641&idx=3&sn=c1694944bc0487ed31c8d16b347559ad&chksm=ec1ff978db68706ef973731b31560b8b3745a95fd07ea07a287cc283e8fa804e6ea329536ed3&token=236193575&lang=zh_CN#rd)

论文提出一种实时语义分割技术——DFANet，不仅减小了 7 倍计算量，突破实时计算边界，而且无需双摄也可实现手机图像的高清虚化。



### 44、[CVPR2019 | OCGAN: 使用具有约束潜在表示的GAN的一类新颖性检测](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247488626&idx=1&sn=a7b6185eeb54f024b488b715631ba626&chksm=ec1ff98bdb68709d2f8c7caf6e1a0dc8484a94ea45cded7a1d423804c8becaa0207202cef94e&token=236193575&lang=zh_CN#rd)

论文主要探究一类新奇检测的问题，类似异常检测，解决方法是利用去噪的编码-解码网络去学习特定类的Latent表示。


### 43、[CVPR 2019 Oral | 华科开源效果超群的人体姿态迁移算法](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247488592&idx=2&sn=c5913784e2637c74bccee2e1f5e6b09d&chksm=ec1ff9a9db6870bfa983705953f9fa311a0fe30154c3aeca8f4e17d4f04512ad361e2a1cb109&token=236193575&lang=zh_CN#rd)
华中科技大学刚刚开源的一款人体姿态迁移算法，其基于GAN思想构建，效果好到简直令人不可思议，论文为CVPR 2019 Oral。


### 42、[CVPR2019 | （Oral）视频跟踪新思路，完全无需手工标注](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247488534&idx=2&sn=ce6ed0d5791e312164379049d1ca25af&chksm=ec1ff9efdb6870f9ee4b990ec3e11fa7bddff156ca4d40dec70bbfd5fa893441bd12b23260d7&token=236193575&lang=zh_CN#rd)

提供了一种新的训练视频跟踪的思路。这个工作的目标就是训练一个神经网络，使得它能帮助我们获得在video中帧与帧之间的semi-dense correspondence。


### 41、[CVPR2019 | 如何看待 CVPR2019 论文 Libra R-CNN（一个全面平衡的目标检测器）？](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247488311&idx=1&sn=093cdc24e056ec3ce3cda89568db1f43&chksm=ec1ffecedb6877d86c661a7e831430faac7cdb38ee5634a1392d2d84e50689a01ae095f4f073&token=1096185081&lang=zh_CN#rd)

本文是CVPR2019 论文 Libra R-CNN作者对整体paper的解析，论文即将开源～



### 40、[CVPR 2019 | 图像压缩重建也能抵御对抗样本，这是一种新的防守策略](http://bbs.cvmart.net/articles/383)

在这篇文章中，我们将介绍一篇关于对抗样本的论文，该论文表示我们可以重构对抗样本而去除掉对抗信息，从而令它不会对分类模型产生危害。


### 39、[CVPR2019 | 行人检测新思路：高级语义特征检测取得精度新突破](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247488257&idx=2&sn=58fd5d1a156b5e4f4d06cd4d187181a9&chksm=ec1ffef8db6877ee969fae220dd2c6d12b4c33b9f0bec78cf9c1d56d5931d3867ad44cbcd23f&token=1096185081&lang=zh_CN#rd)

本文作者将行人检测问题转化为高级语义特征检测的问题，刷新了行人检测精度的新高度！而且作者称代码将开源。


### 38、[CVPR2019 | 人脸聚类——Linkage Based Face Clustering via GCN](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247488093&idx=1&sn=1c9e9c135ef4d0f2a5289d1381d6bcf6&chksm=ec1fffa4db6876b2d25fded2f9a24dbf72fed1cc18926dd021e43f0fb2e1ab85f50898ea5907&token=1068721710&lang=zh_CN#rd)

本次介绍的工作主要就是为了解决“如何确定距离”这个问题，这是CVPR 2019的一个文章“Linkage Based Face Clustering via Graph Convolution Network”，就是通过利用GCN来识别graph的linkage关系的。


### 37、[SKNet——SENet孪生兄弟篇（CVPR2019）](https://zhuanlan.zhihu.com/p/59690223)

启发自皮质神经元根据不同的刺激可动态调节其自身的receptive field，是结合了SE operator，Merge-and-Run Mappings，以及 attention on inception block 思想的产物，实测目前在超分辨的任务上有明确的提升，扩展应用前景还是值得期待的~


### 36、[CVPR2019语义分割论文：Structured Knowledge Distillation for Semantic Seg](https://zhuanlan.zhihu.com/p/59470026)

这是一篇CVPR2019做语义分割任务的文章，在训练好的大的分割模型上运用知识蒸馏的算法，使得比较小的模型也能提高语义分割的性能。


### 35、[CMU和旷视科技开源：KL-Loss目标检测边界框回归新算法（CVPR2019）](https://mp.weixin.qq.com/s/Zuq0HdGdW_FG6PenoT2QZA)

作者提出一个全新的 regression loss，结合kl散度，使得网络可以更好的学习拟合ground truth，让网络更好的学习和收敛(而不被模糊样例造成的大loss干扰)。


### 34、[CVPR2019 | 旷视提出Meta-SR：单一模型实现超分辨率任意缩放因子](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247488018&idx=2&sn=a8cc6e44fe5857ab914da63d2ae239cc&chksm=ec1fffebdb6876fd6e6080e6ddaaed57ca5202f0636f4a4065070ee2adcf21aa687df996782d&token=1068721710&lang=zh_CN#rd)

旷视的CVPR2019论文，论文提出一种全新方法，称之为 Meta-SR，首次通过单一模型解决了超分辨率的任意缩放因子问题（包括非整数因子）


### 33、[CVPR2019 |「准满分」论文：英伟达推出首个跨摄像头汽车跟踪数据集](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247488006&idx=2&sn=6d6c58c683ced2d0a9a030a018840715&chksm=ec1fffffdb6876e90ce21e42791b1826769edae236827f8ca2afb8bdbff114481ad9544b2d47&token=1068721710&lang=zh_CN#rd)

这篇论文主要介绍了英伟达新推出的 CityFlow（流动之城）数据集，是目前世界上第一个支持跨摄像头汽车跟踪及再识别的大型数据集，同时拥有最多的摄像头数量（40）以及最大的空间跨度（> 3 km^2），为智慧城市的解决方案提供了最好的测试平台。


### 32、[CVPR 2019 | 旷视等Oral论文提出GeoNet：基于测地距离的点云分析深度网络](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487956&idx=2&sn=0b1dd72826412afb02bac769a624b709&chksm=ec1ffc2ddb68753bcc1a5cedbc32caeedf08d2fba13770cef4fc06dcd43be4175e3452f337d5&token=1974059303&lang=zh_CN#rd)

基于网格曲面的几何拓扑信息可以为物体语义分析和几何建模提供较强的线索，但是，如此重要的连接性信息在点云中是缺失的。为此，旷视西雅图研究院首次提出一种全新的深度学习网络，称之为 GeoNet，可建模点云所潜在表征的网格曲面特征。


### 31、[CVPR 2019 Oral | 京东AI研究院提出 ScratchDet：随机初始化训练SSD目标检测器](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487923&idx=2&sn=563fcafdef26d870a1547f9d8eef9abb&chksm=ec1ffc4adb68755cbb11b428b5143562f3c3562bbb2ee44d6900931308b731e91bb2be484d6c&token=1974059303&lang=zh_CN#rd)

作者从优化的角度出发，通过实验解释了梯度稳定手段之一的 BatchNorm 是如何帮助随机初始化训练一阶段检测器 SSD，进而结合了 ResNet 与 VGGNet 来加强对小物体的检测。



### 30、[CVPR2019 | R-MVSNet: 一个高精度高效率的三维重建网络](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487857&idx=2&sn=4dfa01ab50391e6778332dfe8aaf8d79&chksm=ec1ffc88db68759e2c42904e192032a6a5cc72bb669561860c2a96320d799abde69b25336757&token=707798739&lang=zh_CN#rd)

MVSNet升级版——“R-MVSNet”，该网络在原MVSNet的基础上进行改进，引入循环神经网络架构，可依序地在深度方向通过GRU单元正则化2D的代价图，较大程度地缓解了内存消耗。


### 29、[CVPR2019目标检测方法进展综述](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487852&idx=1&sn=f2561a58700590469dfac184b8d15db0&chksm=ec1ffc95db6875835ed02f9ce2dc8c0af91498a64548e898910d91950c76fbb1223c5a142854&token=707798739&lang=zh_CN#rd)

本文首先综述近年来二维目标检测的优化方向，之后介绍CVPR2019目标检测最新进展，包括优化IoU的GIoU，优化anchor设计的GA-RPN，以及single-stage detection的FSAF。


### 28、[CVPR2019无人驾驶相关论文](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487852&idx=2&sn=73521aa5a9073eabf8b57e78f59c0a1f&chksm=ec1ffc95db6875834b4bf4de8ec8603e35e22b507a4661e175500856556cfb4b6aca577a2ba2&token=707798739&lang=zh_CN#rd)

CVPR2019无人驾驶相关论文的汇总，包括3D目标检测，立体匹配，单目视觉测距等，更新中。


### 27、[CVPR2019 | Decoders 对于语义分割的重要性](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487822&idx=1&sn=f1b4d5b847f822f0c1dddb8d9a3cd323&chksm=ec1ffcb7db6875a1ccaf885257ad28e2cf564a3e9943c77743ed41881bbb1a6f857ab99d1eb3&token=1388835511&lang=zh_CN#rd)

该文章提出了一种不同于双线性插值的上采样方法，能够更好的建立每个像素之间预测的相关性。得益于这个强大的上采样方法，模型能够减少对特征图分辨率的依赖，能极大的减少运算量。


### 26、[CVPR 2019 | 用异构卷积训练深度CNN：提升效率而不损准确度](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487793&idx=2&sn=7ae2c2f4659325e0f710c387d0436e2f&chksm=ec1ffcc8db6875de847f882b42e2af1d82bb52a425aae68670023a79a19b48c51fefd7736059&token=1388835511&lang=zh_CN#rd)

对于深度卷积神经网络而言，准确度和计算成本往往难以得兼。本文则给出了一个新的思路——使用异构的卷积过滤器；实验表明这种方法能在保证准确度的同时显著降低计算成本。


### 25、[图像分类算法优化技巧：Bag of Tricks for Image Classification](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247486778&idx=2&sn=23582d015eff1d0d5ba0c6f71ca86296&chksm=ec1fe0c3db6869d588af077e6041377193cee8c8eeb069f283bdf6b9a2613bb7dc6b4c7b365a&mpshare=1&scene=1&srcid=0318W4ZKu3BiCVeuKx6lLMrc#rd)

这篇文章是亚马逊科学家介绍CNN网络调优的细节，许多实验是在图像分类算法做的，比如ResNet，作者不仅复现出原论文的结果，在许多网络结构上甚至超出原论文的效果，而且对于目标检测，图像分割算法同样有提升作用。目前论文已被CVPR2019接收。


### 24、[双重注意力网络：中科院自动化所提出新的自然场景图像分割框架（附源码）](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247486107&idx=1&sn=a2912942814134c4361bed3ddf8e7f33&chksm=ec1fe762db686e746aa114a632d8cf1902fd140ec74534e0770e7e98124f94a555ec0b801ee5&mpshare=1&scene=1&srcid=03181r8Vl4jIxjRB3hPJIags#rd)

本文提出了一个新的自然场景图像分割框架，称为双重注意力网络（DANet），引入了一种自注意力机制来分别捕捉空间维度和通道维度上的视觉特征关联。目前论文已被CVPR2019接收。


### 23、[CVPR 2019| ILC：用于自然场景多目标的计数模型](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487752&idx=1&sn=cdb5e1e5d80da6105c04b72f39783891&chksm=ec1ffcf1db6875e75967717accd043f31a5a1dfec16d14c3d807cf0d957d4eaecd02e72a59d6&token=1417050475&lang=zh_CN#rd)

本文提出用于自然场景的计数模型，基于Image-level的方式训练，相较于以往需要Instance-level/point-level/bounding box level等训练方式来说，此模型只要有出现的类别以及各自的数量即可进行训练。


### 22、[CVPR 2019 | 用异构卷积训练深度CNN：提升效率而不损准确度](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487793&idx=2&sn=7ae2c2f4659325e0f710c387d0436e2f&chksm=ec1ffcc8db6875de847f882b42e2af1d82bb52a425aae68670023a79a19b48c51fefd7736059&token=1417050475&lang=zh_CN#rd)

对于深度卷积神经网络而言，准确度和计算成本往往难以得兼，本文则给出了一个新的思路——使用异构的卷积过滤器；实验表明这种方法能在保证准确度的同时显著降低计算成本。



### 21、[CVPR2019 | 西北工业大学开源拥挤人群数据集生成工具，大幅提升算法精度](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487704&idx=2&sn=c659febbcf47b7e43fdeded51565ae3c&chksm=ec1ffd21db6874375764a08603e55f6514f5e4740b53f72b2da89451128707b5795fdd2086da&token=1597346997&lang=zh_CN#rd)

来自西北工业大学的学者提出使用计算机图形工具创建拥挤人群数据集的方法，并开源了他们创建的大型数据集，在此数据集上训练的算法精度获得了大幅提升，超越了之前的state-of-the-art。


### 20、[DaSiamRPN的升级版，视觉目标跟踪之SiamRPN++](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487401&idx=1&sn=cd4845c9aa08a446d449f563c8c9116f&chksm=ec1fe250db686b46270b22fae09134825be802a43a9e63c0587741c470250824b2ccf50dd4fa&token=1597346997&lang=zh_CN#rd)

商汤新工作，DaSiamRPN的升级版：SiamRPN++，在多个跟踪数据集上都是state-of-the-art ，目前论文已被CVPR2019接收（oral）。


### 19、[CVPR 2019 | 让机器帮你做行测题，UCLA朱松纯团队提出关系和类比视觉推理数据集RAVEN](https://mp.weixin.qq.com/s/h38VZnInkuOjkgcEmsTtMg)

为了突破当前视觉推理能力的极限，UCLA 朱松纯团队基于一项更难的人类视觉推理任务——瑞文测试（RPM，例如《行测》中的图形推理题）构建了关系和类比视觉推理数据集 RAVEN。


### 18、[CVPR 2019 | 微软亚研院提出用于语义分割的结构化知识蒸馏](https://mp.weixin.qq.com/s/WvYPf7xHu4TtuDan_Hh_pQ)

该文研究了在语义分割模型的知识蒸馏中引入结构化信息的损失函数，在不改变模型计算量的情况下，使用该方法在Cityscapes数据集上mIoU精度取得了最高达15.17%的提升。


### 17、[CVPR 2019 | 京东AI研究院提出 ScratchDet：随机初始化训练SSD目标检测器](https://mp.weixin.qq.com/s/_WCVvM6sPpsWD8NS8etEKA)

本文介绍了京东AI研究院被接受的一篇 Oral 论文，作者从优化的角度出发，通过实验解释了梯度稳定手段之一的 BatchNorm 是如何帮助随机初始化训练一阶段检测器 SSD，进而结合了 ResNet 与 VGGNet 来加强对小物体的检测。


### 16、[CVPR2019 | 业内最大规模！美图联合清华推出教程类行为数据集 COIN](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487663&idx=1&sn=939fe52ad5d2c71dd750492af718e8cd&chksm=ec1ffd56db68744032a84d19cfbb4fd22ff5d0789237eb7a2e47653c7370e0277e0672e5d9db&token=357316376&lang=zh_CN#rd)

美图和清华团队联合发布了业界规模最大，多样性最丰富的教程类行为数据集 COIN。该数据集在标注结构上采用分层的组织结构，涵盖了多种不同类型的教程类视频。给复杂场景下视频动作时序定位等问题的研究提供了丰富的数据资源。



### 15、[CVPR2019 | Stereo R-CNN 3D 目标检测](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487656&idx=1&sn=f63ec846c0d502980d9ea528c72701d0&chksm=ec1ffd51db68744719ba6cc7525d17fc3c00a5cd0da9f91501346833c58480f9f062fe362ce4&token=1128418914&lang=zh_CN#rd)

这是一篇来自DJI与港科大合作的双目的3d object detection文章，解决立体视觉中的检测问题。整个文章将传统的detection的任务，结合了geometry constraint优化的方式，用在3Ddetection上面还是比较新颖的。


### 14、[CVPR2019 oral | 这个面部3D重建模型，造出了6000多个名人的数字面具](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487646&idx=1&sn=e00277dc49a73264ef9330affba3cb64&chksm=ec1ffd67db687471c1d6d928ab99a4de1bf1e9cf2e0417ca4dcc1aac942d38c4708bfb9ee0d8&token=1128418914&lang=zh_CN#rd)

本文提出了一种新型的面部三维重建模型，效果惊艳。该模型基于自监督学习，使用了来自 YouTube 抓取的 6000 多个名人的视频片段进行训练，该模型可以完全从零开始学习，将面部的多种特征分离再重新组合。


### 13、[CVPR2019 | 医学影像：MIT 团队提出利用学习图像变换进行数据增强](http://bbs.cvmart.net/articles/314/cvpr2019-yi-xue-ying-xiang-mit-tuan-dui-ti-chu-li-yong-xue-xi-tu-xiang-bian-huan-jin-xing-shu-ju-zeng-qiang)

近日，由麻省理工学院（MIT）电子工程与计算机科学（ECCS）实验室多位博士所著的医学影像AI论文被CVPR 2019收录。该团队为了解决医学图像标注数据缺乏的问题，提出了通过学习图像的变换（transforms）进行数据增强的半监督分割方法。



### 12、[CVPR2019 | SiamMask：视频跟踪最高精度](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487638&idx=1&sn=5d3891860d29e994dd1241e19fd2cb19&chksm=ec1ffd6fdb68747980ff7ae61094e708e7e09059daddac75670b2e0cb41ec72dcf5f325ff3ae&token=815081813&lang=zh_CN#rd)

本文介绍一篇非常优秀的视觉跟踪方面的论文，作者提出的新算法SiamMask，在视频跟踪任务上达到最优性能，并且在视频目标分割上取得了当前最快速度。作者来自中科院自动化所，牛津大学等，本文带来一作自动化所王强的解读。


### 11、[CVPR2019 | FSAF：来自CMU的Single-Shot目标检测算法](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487638&idx=2&sn=1e9f26013b3d9ab4fd4137729894606a&chksm=ec1ffd6fdb687479183be59ec102f28bff4a5521903707fef744449e7630252c5298b66f339b&token=815081813&lang=zh_CN#rd)

本文介绍了来自CMU的CVPR2019论文，提出了一个非常优秀的Single-Shot目标检测算法：FSAF。



### 10、[CVPR2019 | AlphaPose升级！上海交大卢策吾团队开源密集人群姿态估计代码](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487597&idx=2&sn=e23ac70a82e066a34a3b9a1ec90cf618&chksm=ec1ffd94db6874822a611ac033913a0c74432fcdfeda2890f64bfdbf5c449df442426112435a&token=815081813&lang=zh_CN#rd)

AlphaPose升级了！上海交大MVIG组(卢策吾团队)构建了CrowdPose数据集，用来衡量算法在拥挤场景中的性能。同时提出了一个高效的算法来解决拥挤人群中的姿态估计问题，实验结果远高于当前最好的算法。


### 9、[CVPR2019 | 实例分割的进阶三级跳：从 Mask R-CNN 到 Hybrid Task Cascade](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487586&idx=1&sn=15560e8b45d330875364272c1f03c068&chksm=ec1ffd9bdb68748d7d6f1d03ce2dd03c77643511dba8311d1bc569c6bd0d5faf9fd9fed5315c&token=65056564&lang=zh_CN#rd)

在本篇论文中，作者提出了一种新的实例分割框架，设计了多任务多阶段的混合级联结构，并且融合了一个语义分割的分支来增强 spatial context。取得了明显优于 Mask R-CNN 和 Cascade Mask R-CNN 的结果。


### 8、[CVPR2019 | 开源分割新算法MS R-CNN，性能超越何恺明Mask R-CNN](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487586&idx=2&sn=aa75de2cf7403292890ce6a1a5640a80&chksm=ec1ffd9bdb68748da1a8c4132c556e604fc3ccf96cd25d9f7f13b29ab16e0a006fb35a3e3ed6&token=65056564&lang=zh_CN#rd)

本文分析了过去的经典分割框架存在的缺陷，并提出基于Mask R-CNN提出一个新的框架Mask Scoring R-CNN，能自动学习出mask quality，试图解决不配准的问题。



### 7、[CVPR2019 | 专门为卷积神经网络设计的训练方法：RePr](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487556&idx=2&sn=34b41d2500564348c3b63c6ee71d8c28&chksm=ec1ffdbddb6874abbf4c02658126d031457702fc43165bc3ff1c58a32000260ba6bbc7fe8afb&token=65056564&lang=zh_CN#rd)

本文提出了一种针对卷积神经网络的训练方法RePr，非常简单有效，在cifar，ImageNet，VQA，object detection上涨点很多，ablation study做的非常充分。



### 6、[CVPR2019 | 审稿排名第一满分论文：让机器人也能「问路」的视觉语言导航新方法](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487556&idx=3&sn=92f66ada3b9a07d25fd8b2427c5ef14a&chksm=ec1ffdbddb6874ab6da373ddec9f9c7c2f8d2c26c6a0f6042de9e0ed46ca3818e5f7d78c5b68&token=65056564&lang=zh_CN#rd)

本文是CVPR满分文章（3个Strong Accept），在5165篇投稿文章中得分排名第一。该论文提出的新方法结合了强化学习和自监督模仿学习两者之长，在视觉-语言导航任务上取得了显著的进步。


### 5、[CVPR2019 | 全景分割：Attention-guided Unified Network](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487527&idx=1&sn=2f798d1036a3bd1b5c6939669fc7f557&chksm=ec1ffddedb6874c85cbbe1d700fb34f8af7d18b3c92c29fb7f30fb69910c1a665059b60663f2&token=65056564&lang=zh_CN#rd)

中国科学院自动化研究所所做关于全景分割问题。本文提出了一个叫做 Attention-guided Unified Network ( AUNet ) 的结构去解决全景分割问题，该方法在MS-COCO数据集上取得了目前最好的结果。


### 4、[CVPR2019 | 6D目标姿态估计，李飞飞夫妇等提出DenseFusion](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487526&idx=1&sn=c3e7968f223e3df383e0406e671f1111&chksm=ec1ffddfdb6874c96c6ea4d7b419be2431f8a73e765a230ed75ac07dc4ec201991e5fe612474&token=65056564&lang=zh_CN#rd)

李飞飞夫妇等研究者提出了 DenseFusion——一种可单独处理两个数据源的异质架构。目前这项工作已被CVPR2019接收。


### 3、[CVPR2019 | 目标检测新文：Generalized Intersection over Union](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487503&idx=1&sn=e98437efda298a9d8fe1a386c5a96601&chksm=ec1ffdf6db6874e03e1e05d438ebd0d295364d01ca8b2741bdad8ffa5d328032ad24ae76a289&token=65056564&lang=zh_CN#rd)

本文提出用IoU这个直接的指标来指导回归任务的学习，用直接指标IoU作为损失函数的缺陷性，提出新的metric来代替L1，L2损失函数，从而提升regression效果。


### 2、[CVPR2019 | 微软，中科大开源基于深度高分辨表示学习的姿态估计算法](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487487&idx=2&sn=dd7b37bbb1aba55cc2f9aa450e09297b&chksm=ec1fe206db686b10504ec92942ea899911c724d152584633e55370745d33a194c4e9e5b84c32&token=65056564&lang=zh_CN#rd)

来自微软和中国科技大学研究学者提出了基于深度高分辨表示学习的姿态估计算法，论文和相应代码甫一公布，立刻引起大家的关注，不到一天之内，github上已有将近50颗星。


### 1、[CVPR2019 | Guided Anchoring: 物体检测器也能自己学 Anchor](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247487300&idx=1&sn=3b5f6386f9a31acf48f377cf23e6af6f&chksm=ec1fe2bddb686bab3b569768ff2b5bec60f10606352b72b861bbb0d616f61f15a91996b90fb0&token=65056564&lang=zh_CN#rd)

物体检测领域论文"Region Proposal by Guided Anchoring"解读，这篇 paper 的方法用在了 COCO Challenge 2018 检测任务的冠军方法中，在极高的 baseline 上涨了1个点。论文目前已被CVPR2019接收。

## [人脸技术篇](https://mp.weixin.qq.com/s/L1W9YAAA6jE6UrieRHIpcw)
## [超分辨率篇](https://mp.weixin.qq.com/s/aHkczVDs5r9pRyzMYmE6sg)

> https://github.com/extreme-assistant/cvpr2019
